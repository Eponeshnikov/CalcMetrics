{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ck7466Jy3RT7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3120,
     "status": "ok",
     "timestamp": 1637436056918,
     "user": {
      "displayName": "Sasha Ы",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlZZRzcgVOZi8RUdHSNh--Wx0fo3yCma39ezQATA=s64",
      "userId": "06903974888959639026"
     },
     "user_tz": -180
    },
    "id": "ck7466Jy3RT7",
    "outputId": "2eb5ca0b-b2c7-4968-87bc-9bed932f966e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyGithub in /usr/local/lib/python3.7/dist-packages (1.55)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
      "Requirement already satisfied: pyjwt>=2.0 in /usr/local/lib/python3.7/dist-packages (from PyGithub) (2.3.0)\n",
      "Requirement already satisfied: pynacl>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from PyGithub) (1.4.0)\n",
      "Requirement already satisfied: deprecated in /usr/local/lib/python3.7/dist-packages (from PyGithub) (1.2.13)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from pynacl>=1.4.0->PyGithub) (1.15.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pynacl>=1.4.0->PyGithub) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.21)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated->PyGithub) (1.13.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install PyGithub requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "879f3bb1-9ac7-4cf7-b8eb-895aa0984a86",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 885,
     "status": "ok",
     "timestamp": 1637436061714,
     "user": {
      "displayName": "Sasha Ы",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlZZRzcgVOZi8RUdHSNh--Wx0fo3yCma39ezQATA=s64",
      "userId": "06903974888959639026"
     },
     "user_tz": -180
    },
    "id": "879f3bb1-9ac7-4cf7-b8eb-895aa0984a86",
    "outputId": "5e6cadac-01af-44fd-cc49-6051b2ef2d02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6347f936-2acf-4eef-8b73-6e2bbf508903",
   "metadata": {
    "executionInfo": {
     "elapsed": 326,
     "status": "ok",
     "timestamp": 1637450392424,
     "user": {
      "displayName": "Sasha Ы",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlZZRzcgVOZi8RUdHSNh--Wx0fo3yCma39ezQATA=s64",
      "userId": "06903974888959639026"
     },
     "user_tz": -180
    },
    "id": "E-wfsbrgPta7"
   },
   "outputs": [],
   "source": [
    "def read_repos(txt):\n",
    "    with open(txt, 'r') as f:\n",
    "        repos = f.readlines()\n",
    "        for i in range(len(repos)):\n",
    "            repos[i] = repos[i].rstrip()\n",
    "    return repos\n",
    "\n",
    "def get_repo_names(repos):\n",
    "    user_repo = []\n",
    "    for i, repo in enumerate(repos):\n",
    "        spl = repo.split(\"/\")\n",
    "        name_repo = spl[len(spl) - 1]\n",
    "        username = spl[len(spl) - 2]\n",
    "        user_repo.append([username, name_repo])\n",
    "    return user_repo\n",
    "\n",
    "def grab_issues(user_repo, client, count=None, requests=None):\n",
    "    issues = []\n",
    "    start_req = rate_limit(client)\n",
    "    r_issues = user_repo.get_issues(state=\"all\")\n",
    "    totalCount = r_issues.totalCount\n",
    "    for i in r_issues:\n",
    "        issues.append(i)\n",
    "        if count != None:\n",
    "            if len(issues) == count:\n",
    "                break\n",
    "        if requests != None:\n",
    "            if start_req - rate_limit(client) >= requests:\n",
    "                break\n",
    "    return issues, totalCount\n",
    "\n",
    "def grab_commits(user_repo, client, count=None, requests=None):\n",
    "    commits = []\n",
    "    start_req = rate_limit(client)\n",
    "    r_commits = user_repo.get_commits()\n",
    "    totalCount = r_commits.totalCount\n",
    "    for i in r_commits:\n",
    "        commits.append(i)\n",
    "        if count != None:\n",
    "            if len(commits) == count:\n",
    "                break\n",
    "        if requests != None:\n",
    "            if start_req - rate_limit(client) >= requests:\n",
    "                break\n",
    "    return commits, totalCount\n",
    "\n",
    "def grab_wf(user_repo, client, count=None, requests=None):\n",
    "    wf = []\n",
    "    start_req = rate_limit(client)\n",
    "    r_wf = user_repo.get_workflows()\n",
    "    totalCount = r_wf.totalCount\n",
    "    for i in r_wf:\n",
    "        wf.append(i)\n",
    "        if count != None:\n",
    "            if len(wf) == count:\n",
    "                break\n",
    "        if requests != None:\n",
    "            if start_req - rate_limit(client) >= requests:\n",
    "                break\n",
    "    return wf, totalCount\n",
    "\n",
    "def grab_pr(user_repo, client, count=None, requests=None):\n",
    "    pr = []\n",
    "    start_req = rate_limit(client)\n",
    "    r_pr = user_repo.get_pulls(state=\"all\")\n",
    "    totalCount = r_pr.totalCount\n",
    "    for i in r_pr:\n",
    "        pr.append(i)\n",
    "        if count != None:\n",
    "            if len(pr) == count:\n",
    "                break\n",
    "        if requests != None:\n",
    "            if start_req - rate_limit(client) >= requests:\n",
    "                break\n",
    "    return pr, totalCount\n",
    "\n",
    "def avg_time2reaction_and_mess_bug_reports(issues):\n",
    "    bug_times = []\n",
    "    mess_bug = 0\n",
    "    mess_bug_num = 0\n",
    "    for i in issues:\n",
    "        if 'bug' in i.title:\n",
    "            mess_bug +=i.comments\n",
    "            mess_bug_num += 1\n",
    "            if i.closed_at is not None:\n",
    "                bug_times.append((i.closed_at - i.created_at).total_seconds())\n",
    "    avg_bug_time = 0\n",
    "    if len(bug_times) != 0:\n",
    "        avg_bug_time = sum(bug_times)/len(bug_times)\n",
    "    avg_mess_bug = mess_bug/mess_bug_num\n",
    "    return avg_bug_time, avg_mess_bug\n",
    "\n",
    "def avg_dur_pr(pullrequest):\n",
    "    pr_times = []\n",
    "    for pr in pullrequest:\n",
    "        if pr.closed_at is not None:\n",
    "            pr_times.append((pr.closed_at - pr.created_at).total_seconds())\n",
    "    avg_pr_time = sum(pr_times)/len(pr_times)\n",
    "    return avg_pr_time\n",
    "\n",
    "def duration_of_pipelines(workflows, client, count=None, requests=None):\n",
    "    w_time = []\n",
    "    total_count = []\n",
    "    start_req = rate_limit(client)\n",
    "    for w in workflows:\n",
    "        run_time = []\n",
    "        runs = w.get_runs()\n",
    "        total_count.append(runs.totalCount)\n",
    "        for r in runs:\n",
    "            try:\n",
    "                t = r.timing().run_duration_ms\n",
    "                run_time.append(t)\n",
    "                if count != None:\n",
    "                    if len(run_time) == count:\n",
    "                        break\n",
    "                if requests != None:\n",
    "                    if start_req - rate_limit(client) >= requests/len(workflows):\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        w_time.append(run_time)\n",
    "    avg_wt = []\n",
    "    for wt in w_time:\n",
    "        if len(wt) != 0:\n",
    "            avg_wt.append(sum(wt)/len(wt)/1000)\n",
    "    return avg_wt, total_count\n",
    "\n",
    "def num_branches(user_repo):\n",
    "    return user_repo.get_branches().totalCount\n",
    "\n",
    "def commits_perday_perdev(commits):\n",
    "    df = pd.DataFrame(columns=(\"author\", \"date\"))\n",
    "    for i, c in enumerate(commits):\n",
    "        try:\n",
    "            df.loc[i] = [c.commit.author.name] + [time.mktime(c.commit.author.date.timetuple())]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    authors = set(df['author'])\n",
    "    avg_mess_per_day_per_dev = []\n",
    "    for author in authors:\n",
    "        dates = df.iloc[df.index[df['author'] == author]]['date']\n",
    "        delta = (dates.max() - dates.min())/86400\n",
    "        if delta != 0:\n",
    "            avg_mess_per_day_per_dev.append(len(dates)/delta)\n",
    "    return avg_mess_per_day_per_dev\n",
    "\n",
    "def contr_per_pr(pullrequest, client, count=None, requests=None):\n",
    "    pull_users = []\n",
    "    start_req = rate_limit(client)\n",
    "    for i, pul in enumerate(pullrequest):\n",
    "        comments = pul.get_comments()\n",
    "        commits = pul.get_commits()\n",
    "        users = []\n",
    "        for comm in comments:\n",
    "            try:\n",
    "                if comm.user.name != None:\n",
    "                    users.append(comm.user.name)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            if requests != None:\n",
    "                if start_req - rate_limit(client) >= requests:\n",
    "                    break\n",
    "        for comm in commits:\n",
    "            if comm.commit.author.name != None:\n",
    "                users.append(comm.commit.author.name)\n",
    "            if requests != None:\n",
    "                if start_req - rate_limit(client) >= requests:\n",
    "                    break\n",
    "        if count != None:\n",
    "            if i == count:\n",
    "                break\n",
    "        if requests != None:\n",
    "            if start_req - rate_limit(client) >= requests:\n",
    "                break\n",
    "        pull_users.append(users)\n",
    "    contr_pull = []\n",
    "    for u in pull_users:\n",
    "        contr = []\n",
    "        unique = set(u)\n",
    "        for un in unique:\n",
    "            contr.append(len(np.where(np.array(u) == un)[0]))\n",
    "        contr_pull.append(contr)\n",
    "    return contr_pull\n",
    "        \n",
    "\n",
    "\n",
    "from github import Github\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "# Github username\n",
    "\n",
    "def rate_limit(client):\n",
    "    return client.get_rate_limit().core.remaining\n",
    "\n",
    "def generate_metrics(i):\n",
    "    t = read_repos('tokens.txt')\n",
    "    token = t[i%len(t)]\n",
    "    client = Github(token)\n",
    "    r_ = read_repos('repos.txt')\n",
    "    user_repos = get_repo_names(r_)\n",
    "    user = client.get_user(user_repos[i][0])\n",
    "    user_repo = user.get_repo(user_repos[i][1])\n",
    "    print(user_repos[i][0], user_repos[i][1])\n",
    "    print(\"Rate limit at start:\", rate_limit(client))\n",
    "    print(\"Get Issues\")\n",
    "    issues, count_issues = grab_issues(user_repo, client, requests=50)\n",
    "    print(\"Get Workflows\")\n",
    "    wf, count_wf = grab_wf(user_repo, client, requests=50)\n",
    "    print(\"Get Pulls\")\n",
    "    pullreq, count_pullreq = grab_pr(user_repo, client, requests=250)\n",
    "    print(\"Get Commits\")\n",
    "    commits, count_commits = grab_commits(user_repo, client, requests=150)\n",
    "    print(\"Rate limit after grub:\", rate_limit(client))\n",
    "    print(\"Get Branches\")\n",
    "    num_branch = num_branches(user_repo)\n",
    "    print(\"Get bug report lifetime, avg comments in bur report\")\n",
    "    avg_bug_time, avg_mess_bug = avg_time2reaction_and_mess_bug_reports(issues)\n",
    "    print(\"Get Pull Request lifetime\")\n",
    "    avg_pr_time = avg_dur_pr(pullreq)\n",
    "    print(\"Get bug comments per day per dev\")\n",
    "    avg_mess_per_day_per_dev = commits_perday_perdev(commits)\n",
    "    r_lim = int(rate_limit(client)/6)\n",
    "    print(\"Get CI/DI\")\n",
    "    avg_wt, count_avg_wt = duration_of_pipelines(wf, client, requests=600)\n",
    "    print(\"Get Amount of contribution in Pull request\")\n",
    "    contr_pull = contr_per_pr(pullreq, client, requests=1200)\n",
    "    metric_dict = {\"user_repo\":user_repos[i][0] + '_' + user_repos[i][1],\n",
    "                   \"count_issues\":count_issues,\n",
    "                   \"count_wf\":count_wf,\n",
    "                   \"count_pullreq\":count_pullreq,\n",
    "                   \"count_commits\":count_commits,\n",
    "                   \"num_branch\":num_branch,\n",
    "                   \"avg_bug_time\":avg_bug_time,\n",
    "                   \"avg_mess_bug\":avg_mess_bug,\n",
    "                   \"avg_pr_time\":avg_pr_time,\n",
    "                   \"avg_mess_per_day_per_dev\":avg_mess_per_day_per_dev,\n",
    "                   \"avg_wt\":avg_wt,\n",
    "                   \"count_avg_wt\":count_avg_wt,\n",
    "                   \"contr_pull\":contr_pull\n",
    "                   }\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1996624a-1601-47f7-990b-144ac5e99bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spring-cloud spring-cloud-gateway\n",
      "Rate limit at start: 4998\n",
      "Get Issues\n",
      "Get Workflows\n",
      "Get Pulls\n",
      "Get Commits\n",
      "Rate limit after grub: 4860\n",
      "Get Branches\n",
      "Get bug report lifetime, avg comments in bur report\n",
      "Get Pull Request lifetime\n",
      "Get bug comments per day per dev\n",
      "Get CI/DI\n",
      "Get Amount of contribution in Pull request\n"
     ]
    }
   ],
   "source": [
    "res = generate_metrics(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7b1080c4-0ba6-4548-9a94-506c3a03b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_metr_dict = {\"Average time-to-reaction in bug reports (sec)\":res['avg_bug_time'],\n",
    "                 \"Duration of CI/CD pipeline (sec)\":sum([res['count_avg_wt'][i]*res['avg_wt'][i] for i in range(len(res['avg_wt']))]),\n",
    "                 \"Number of branches in Git\":res['num_branch'],\n",
    "                 \"Average number of messages in a bug report\":res['avg_mess_bug'],\n",
    "                 \"Average lifetime duration of a pull request (sec)\":res['avg_pr_time'],\n",
    "                 \"Average Number of commits per day per developer\":np.array([i for i in res['avg_mess_per_day_per_dev'] if i < np.percentile(res['avg_mess_per_day_per_dev'], 90)]).mean(),\n",
    "                 \"Number of commits\":res['count_commits'],\n",
    "                 \"Average amount of contribution per pull request\":np.sum(np.sum(res['contr_pull']))/len(res['contr_pull']),\n",
    "                 \"Amount of contribution of all pull requests\":np.sum(np.sum(res['contr_pull']))/len(res['contr_pull'])*res['count_pullreq'],\n",
    "                 \"Count of pull requests\":res['count_pullreq']\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbde596-c79b-4e00-b803-268dee68a48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "83d7090f-75ae-449f-80e2-78ed6875a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_metr_df = pd.DataFrame(git_metr_dict, index=[0])\n",
    "git_metr_df.to_csv('csv/' + res['user_repo'].split('_')[1] + '/data/git.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fc0aa6-ae6c-4a4f-969b-dda65576dc2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UnwRdBN5QVKA",
   "metadata": {},
   "outputs": [
    {
     "ename": "GithubException",
     "evalue": "500 null",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"d:\\work\\pythonprojects\\univerinnopolis\\venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"d:\\work\\pythonprojects\\univerinnopolis\\venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"d:\\work\\pythonprojects\\univerinnopolis\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"d:\\work\\pythonprojects\\univerinnopolis\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"d:\\work\\pythonprojects\\univerinnopolis\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\sasha\\AppData\\Local\\Temp/ipykernel_6064/2432923574.py\", line 33, in generate_metrics\n  File \"C:\\Users\\sasha\\AppData\\Local\\Temp/ipykernel_6064/2932010994.py\", line 9, in duration_of_pipelines\n  File \"d:\\work\\pythonprojects\\univerinnopolis\\venv\\lib\\site-packages\\github\\PaginatedList.py\", line 56, in __iter__\n    newElements = self._grow()\n  File \"d:\\work\\pythonprojects\\univerinnopolis\\venv\\lib\\site-packages\\github\\PaginatedList.py\", line 67, in _grow\n    newElements = self._fetchNextPage()\n  File \"d:\\work\\pythonprojects\\univerinnopolis\\venv\\lib\\site-packages\\github\\PaginatedList.py\", line 199, in _fetchNextPage\n    headers, data = self.__requester.requestJsonAndCheck(\n  File \"d:\\work\\pythonprojects\\univerinnopolis\\venv\\lib\\site-packages\\github\\Requester.py\", line 353, in requestJsonAndCheck\n    return self.__check(\n  File \"d:\\work\\pythonprojects\\univerinnopolis\\venv\\lib\\site-packages\\github\\Requester.py\", line 378, in __check\n    raise self.__createException(status, responseHeaders, output)\ngithub.GithubException.GithubException: 500 null\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mGithubException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6064/2181041737.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerate_metrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\work\\pythonprojects\\univerinnopolis\\venv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\work\\pythonprojects\\univerinnopolis\\venv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\work\\pythonprojects\\univerinnopolis\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mGithubException\u001b[0m: 500 null"
     ]
    }
   ],
   "source": [
    "results = Parallel(n_jobs=20)(delayed(generate_metrics)(i) for i in range(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "qZZsGfabVr2e",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1637448349307,
     "user": {
      "displayName": "Sasha Ы",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlZZRzcgVOZi8RUdHSNh--Wx0fo3yCma39ezQATA=s64",
      "userId": "06903974888959639026"
     },
     "user_tz": -180
    },
    "id": "qZZsGfabVr2e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "git_metrics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
